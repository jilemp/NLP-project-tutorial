# ğŸ”— Spam Detection from URLs using NLP & SVM

This repository presents a Natural Language Processing (NLP) project aimed at detecting **spam URLs** using machine learning. The project performs text cleaning, feature extraction, and classification using an SVM model with grid search tuning.

---

## ğŸ“ Project Structure

```
ğŸ“¦ URL-Spam-Detection/
â”œâ”€â”€ explore.ipynb         # Jupyter notebook with full analysis
â”œâ”€â”€ README.md                 # Project description and usage
```

---

## ğŸ“Š Dataset

- ğŸ“‚ Source: [4Geeks Academy GitHub - `url_spam.csv`](https://github.com/4GeeksAcademy/NLP-project-tutorial/)
- ğŸ’¡ Contents:
  - URL text
  - Spam labels (binary classification)
- ğŸ” Initial cleanup removed over **600 duplicate entries**

---

## ğŸ§¹ NLP Preprocessing

- âœ… Lowercasing, stopwords removal (`nltk`)
- ğŸ”¤ Lemmatization with `WordNetLemmatizer`
- ğŸ”§ Regex cleanup
- â˜ï¸ WordCloud for spam vs. non-spam terms

---

## ğŸ§  Model & Evaluation

- âœ¨ **Model**: Support Vector Machine (SVM)
- ğŸ” **Tuning**: `GridSearchCV` with `RepeatedStratifiedKFold`
- ğŸ“ˆ **Metrics**: Classification report including Precision, Recall, F1-score

---

## ğŸš€ How to Run

1. Clone the repository

```bash
git clone https://github.com/jilemp/URL-Spam-Detection.git
cd URL-Spam-Detection
```

2. Install dependencies

```bash
pip install -r requirements.txt
```

3. Launch the notebook

```bash
jupyter notebook "explore.ipynb"
```

---

## ğŸ“š Libraries Used

- `pandas`, `numpy`
- `nltk`, `regex`
- `matplotlib`, `wordcloud`
- `sklearn`

---

## ğŸ“¬ Contact

Project developed as part of 4Geeks Academy â€” NLP Curriculum.
Feel free to open an issue or fork the repo for improvements!
